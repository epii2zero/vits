test0:
  text: "Several recent end-to-end text-to-speech"
  length_scale: [[0.7, 0, 0.5], [1.3, 0.5, 1]]
  sid: 2

test1:
  text: "Several recent end-to-end text-to-speech (TTS) models enabling single-stage training
        and parallel sampling have been proposed, but their sample quality does not match that of
        two-stage TTS systems. In this work, we present a parallel end-to-end TTS method that
        generates more natural sounding audio than current two-stage models. Our method adopts
        variational inference augmented with normalizing flows and an adversarial training process,
        which improves the expressive power of generative modeling. We also propose a stochastic
        duration predictor to synthesize speech with diverse rhythms from input text.
        With the uncertainty modeling over latent variables and the stochastic duration predictor,
        our method expresses the natural one-to-many relationship in which a text input can be
        spoken in multiple ways with different pitches and rhythms. A subjective human evaluation
        (mean opinion score, or MOS) on the LJ Speech, a single speaker dataset, shows that our
        method outperforms the best publicly available TTS systems and achieves a MOS comparable
        to ground truth."
  length_scale: [[1, 0, 0.4], [0.7, 0.4, 0.8], [1.3, 0.8, 1]]
  sid: 2

test2:
  text: "Several recent end-to-end text-to-speech (TTS) models enabling single-stage training
        and parallel sampling have been proposed, but their sample quality does not match that of
        two-stage TTS systems. In this work, we present a parallel end-to-end TTS method that
        generates more natural sounding audio than current two-stage models. Our method adopts
        variational inference augmented with normalizing flows and an adversarial training process,
        which improves the expressive power of generative modeling. We also propose a stochastic
        duration predictor to synthesize speech with diverse rhythms from input text.
        With the uncertainty modeling over latent variables and the stochastic duration predictor,
        our method expresses the natural one-to-many relationship in which a text input can be
        spoken in multiple ways with different pitches and rhythms. A subjective human evaluation
        (mean opinion score, or MOS) on the LJ Speech, a single speaker dataset, shows that our
        method outperforms the best publicly available TTS systems and achieves a MOS comparable
        to ground truth."
  length_scale: 0.8
  sid: 1

test3:
  text: "Several recent end-to-end text-to-speech (TTS) models enabling single-stage training
        and parallel sampling have been proposed, but their sample quality does not match that of
        two-stage TTS systems. In this work, we present a parallel end-to-end TTS method that
        generates more natural sounding audio than current two-stage models. Our method adopts
        variational inference augmented with normalizing flows and an adversarial training process,
        which improves the expressive power of generative modeling. We also propose a stochastic
        duration predictor to synthesize speech with diverse rhythms from input text.
        With the uncertainty modeling over latent variables and the stochastic duration predictor,
        our method expresses the natural one-to-many relationship in which a text input can be
        spoken in multiple ways with different pitches and rhythms. A subjective human evaluation
        (mean opinion score, or MOS) on the LJ Speech, a single speaker dataset, shows that our
        method outperforms the best publicly available TTS systems and achieves a MOS comparable
        to ground truth."
  length_scale: 0.8
  sid: 1

test4:
  text: "Several recent end-to-end text-to-speech (TTS) models enabling single-stage training
        and parallel sampling have been proposed, but their sample quality does not match that of
        two-stage TTS systems. In this work, we present a parallel end-to-end TTS method that
        generates more natural sounding audio than current two-stage models. Our method adopts
        variational inference augmented with normalizing flows and an adversarial training process,
        which improves the expressive power of generative modeling. We also propose a stochastic
        duration predictor to synthesize speech with diverse rhythms from input text.
        With the uncertainty modeling over latent variables and the stochastic duration predictor,
        our method expresses the natural one-to-many relationship in which a text input can be
        spoken in multiple ways with different pitches and rhythms. A subjective human evaluation
        (mean opinion score, or MOS) on the LJ Speech, a single speaker dataset, shows that our
        method outperforms the best publicly available TTS systems and achieves a MOS comparable
        to ground truth."
  length_scale: 1.2
  sid: 1

test5:
  text: "안녕하세요 한국어 입력 테스트 입니다. Good morning 굿모닝 입니다."
  length_scale: 1
  sid: 1